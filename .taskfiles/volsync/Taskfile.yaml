---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

# Taskfile used to manage certain VolSync tasks for a given application, limitations are as followed.
#   1. Fluxtomization, HelmRelease, PVC, ReplicationSource all have the same name (e.g. plex)
#   2. ReplicationSource and ReplicationDestination are a Restic repository
#   3. Each application only has one PVC that is being replicated

vars:
  VOLSYNC_RESOURCES_DIR: "{{.ROOT_DIR}}/.taskfiles/volsync/resources"

tasks:
  state-*:
    desc: Suspend or resume Volsync
    cmds:
      - flux --namespace storage {{.STATE}} kustomization volsync
      - flux --namespace storage {{.STATE}} helmrelease volsync
      - kubectl --namespace storage scale deployment volsync --replicas {{if eq .STATE "suspend"}}0{{else}}1{{end}}
    vars:
      STATE: "{{index .MATCH 0}}"
    preconditions:
      - '[[ "{{.STATE}}" == "suspend" || "{{.STATE}}" == "resume" ]]'
      - which flux kubectl

  unlock:
    desc: Unlock all restic source repos
    cmds:
      - for: { var: SOURCES, split: "\n" }
        cmd: kubectl --namespace {{splitList "," .ITEM | first}} patch --field-manager=flux-client-side-apply replicationsources {{splitList "," .ITEM | last}} --type merge --patch "{\"spec\":{\"kopia\":{\"unlock\":\"{{now | unixEpoch}}\"}}}"
    vars:
      SOURCES:
        sh: kubectl get replicationsources --all-namespaces --no-headers --output=jsonpath='{range .items[*]}{.metadata.namespace},{.metadata.name}{"\n"}{end}'
    preconditions:
      - which kubectl

  snapshot:
    desc: Snapshot an app [NS=default] [APP=required]
    cmds:
      - kubectl --namespace {{.NS}} patch replicationsources {{.APP}} --type merge -p '{"spec":{"trigger":{"manual":"{{now | unixEpoch}}"}}}'
      - until kubectl --namespace {{.NS}} get job/{{.JOB}} &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/{{.JOB}} --for=condition=complete --timeout=120m
    vars:
      NS: '{{.NS | default "default"}}'
      JOB: volsync-src-{{.APP}}
    requires:
      vars: [APP]
    preconditions:
      - kubectl --namespace {{.NS}} get replicationsources {{.APP}}
      - which kubectl

  restore:
    desc: Restore an app [NS=default] [APP=required] [PREVIOUS=required]
    cmds:
      # Suspend ALL ArgoCD management layers to prevent interference
      #- echo "Suspending ArgoCD management layers..."
      #- kubectl patch application -n argocd applications --type=json -p='[{"op":"remove","path":"/spec/syncPolicy/automated"}]'
      #- kubectl patch application -n argocd applicationsets --type=json -p='[{"op":"remove","path":"/spec/syncPolicy/automated"}]'
      #- echo "Suspended root 'applications' and 'applicationsets' Applications"
      #- sleep 10
      # Suspend the target Application and its resources Application (if it exists)
      #- kubectl patch application -n argocd {{.APP}} --type=json -p='[{"op":"remove","path":"/spec/syncPolicy/automated"}]' || true
      #- kubectl patch application -n argocd {{.APP}}-resources --type=json -p='[{"op":"remove","path":"/spec/syncPolicy/automated"}]' || true
      #- echo "Suspended '{{.APP}}' and '{{.APP}}-resources' Applications"
      #- sleep 5

      # Scale down
      - kubectl --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas 0
      - kubectl --namespace {{.NS}} wait pod --for=delete --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m

      # Restore
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/replicationdestination.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/volsync-dst-{{.APP}}-manual &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/volsync-dst-{{.APP}}-manual --for=condition=complete --timeout=120m
      - kubectl --namespace {{.NS}} delete replicationdestination {{.APP}}-manual

      # Resume the target Application and its resources Application
      #- kubectl patch application -n argocd {{.APP}} --type=merge -p '{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}' || true
      #- kubectl patch application -n argocd {{.APP}}-resources --type=merge -p '{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}' || true
      #- echo "Resumed '{{.APP}}' and '{{.APP}}-resources' Applications"
      #- sleep 5
      # Resume root ArgoCD Applications
      #- kubectl patch application -n argocd applications --type=merge -p '{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}'
      #- kubectl patch application -n argocd applicationsets --type=merge -p '{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}'
      #- echo "Resumed root 'applications' and 'applicationsets' Applications"
      #- sleep 5
      # Force sync to bring the app back up
      #- kubectl patch application -n argocd {{.APP}} --type=merge -p '{"operation":{"initiatedBy":{"username":"task-volsync-restore"},"sync":{"revision":"HEAD"}}}' || true
      #- kubectl --namespace {{.NS}} wait pod --for=condition=ready #--selector="app.kubernetes.io/name={{.APP}}" --timeout=5m
    vars:
      NS: '{{.NS | default "default"}}'
      CONTROLLER:
        sh: kubectl --namespace {{.NS}} get deployment {{.APP}} &>/dev/null && echo deployment || echo statefulset
    env:
      NS: "{{.NS}}"
      APP: "{{.APP}}"
      PREVIOUS: "{{.PREVIOUS}}"
      CLAIM:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.sourcePVC}'
      ACCESS_MODES:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.accessModes}'
      STORAGE_CLASS_NAME:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.storageClassName}'
      PUID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsUser}'
      PGID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsGroup}'
    requires:
      vars: [APP, PREVIOUS]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/replicationdestination.yaml.j2
      - which kubectl minijinja-cli argocd

  unlock-local:
    desc: Unlock a restic source repo from local machine [NS=default] [APP=required]
    cmds:
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/unlock.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/volsync-unlock-{{.APP}} &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/volsync-unlock-{{.APP}} --for condition=complete --timeout=5m
      - stern --namespace {{.NS}} job/volsync-unlock-{{.APP}} --no-follow
      - kubectl --namespace {{.NS}} delete job volsync-unlock-{{.APP}}
    vars:
      NS: '{{.NS | default "default"}}'
    env:
      NS: "{{.NS}}"
      APP: "{{.APP}}"
    requires:
      vars: [APP]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/unlock.yaml.j2
      - which kubectl minijinja-cli stern

  unstuck:
    desc: Fix a stuck VolSync snapshot [NS=default] [APP=required]
    summary: |
      This task attempts to fix a stuck VolSync snapshot by:
      1. Deleting the ReplicationSource
      2. Force deleting the stuck VolumeSnapshot
      3. Force deleting the VolumeSnapshotContent if it exists
      4. Reconciling the application's Kustomization to recreate the ReplicationSource
      5. Manually triggering a new snapshot
    cmds:
      - bash {{.VOLSYNC_RESOURCES_DIR}}/unstick.sh {{.NS}} {{.APP}}
    vars:
      NS: '{{.NS | default "default"}}'
    requires:
      vars: [APP]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/unstick.sh
      - which kubectl flux

  migrate-to-nfs:
    desc: Migrate a VolSync app to NFS storage [NS=default] [APP=required] [DELETE_PVCS=false]
    summary: |
      This task migrates a VolSync app to use NFS storage classes by:
      1. Suspending the application's kustomization
      2. Deleting the existing ReplicationSource and ReplicationDestination
      3. Optionally deleting PVCs if DELETE_PVCS=true
      4. Resuming the application's kustomization to recreate resources with NFS storage
    cmds:
      - bash {{.ROOT_DIR}}/volsync-migrate-to-nfs.sh -n {{.NS}} -a {{.APP}} {{if eq .DELETE_PVCS "true"}}-d{{end}}
    vars:
      NS: '{{.NS | default "default"}}'
      DELETE_PVCS: '{{.DELETE_PVCS | default "false"}}'
    requires:
      vars: [APP]
    preconditions:
      - test -f {{.ROOT_DIR}}/volsync-migrate-to-nfs.sh
      - which kubectl flux

  migrate-all-to-nfs:
    desc: Migrate all VolSync apps to NFS storage [DELETE_PVCS=false]
    summary: |
      This task migrates all VolSync apps to use NFS storage classes by:
      1. Running the migrate-to-nfs task for each app with a ReplicationSource
      2. Optionally deleting PVCs if DELETE_PVCS=true
      Note: This does NOT migrate data. Use migrate-data-to-nfs for data migration.
    cmds:
      - bash {{.ROOT_DIR}}/migrate-all-volsync-apps.sh {{if eq .DELETE_PVCS "true"}}-d{{end}}
    vars:
      DELETE_PVCS: '{{.DELETE_PVCS | default "false"}}'
    preconditions:
      - test -f {{.ROOT_DIR}}/migrate-all-volsync-apps.sh
      - which kubectl flux

  migrate-data-to-nfs:
    desc: Migrate VolSync app data from iSCSI to NFS storage [NS=default] [APP=required]
    summary: |
      This task migrates VolSync app data from iSCSI to NFS storage by:
      1. Suspending the application's kustomization
      2. Creating a temporary ReplicationDestination on NFS
      3. Triggering a snapshot from iSCSI to NFS
      4. Creating a new PVC from the NFS ReplicationDestination
      5. Replacing the original PVC with the NFS one
      6. Resuming the application's kustomization
    cmds:
      - bash {{.ROOT_DIR}}/volsync-migrate-data-to-nfs.sh -n {{.NS}} -a {{.APP}}
    vars:
      NS: '{{.NS | default "default"}}'
    requires:
      vars: [APP]
    preconditions:
      - test -f {{.ROOT_DIR}}/volsync-migrate-data-to-nfs.sh
      - which kubectl flux

  migrate-all-data-to-nfs:
    desc: Migrate all VolSync apps data from iSCSI to NFS storage
    summary: |
      This task migrates all VolSync apps data from iSCSI to NFS storage by:
      1. Running the migrate-data-to-nfs task for each app with a ReplicationSource
    cmds:
      - bash {{.ROOT_DIR}}/migrate-all-volsync-data-to-nfs.sh
    preconditions:
      - test -f {{.ROOT_DIR}}/migrate-all-volsync-data-to-nfs.sh
      - which kubectl flux
